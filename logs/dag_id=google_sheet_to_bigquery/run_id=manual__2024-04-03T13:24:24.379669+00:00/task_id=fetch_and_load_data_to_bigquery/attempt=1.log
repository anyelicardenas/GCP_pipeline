[2024-04-03T13:24:28.950+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: google_sheet_to_bigquery.fetch_and_load_data_to_bigquery manual__2024-04-03T13:24:24.379669+00:00 [queued]>
[2024-04-03T13:24:28.963+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: google_sheet_to_bigquery.fetch_and_load_data_to_bigquery manual__2024-04-03T13:24:24.379669+00:00 [queued]>
[2024-04-03T13:24:28.964+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 2
[2024-04-03T13:24:28.994+0000] {taskinstance.py:2217} INFO - Executing <Task(PythonOperator): fetch_and_load_data_to_bigquery> on 2024-04-03 13:24:24.379669+00:00
[2024-04-03T13:24:29.000+0000] {standard_task_runner.py:60} INFO - Started process 7106 to run task
[2024-04-03T13:24:29.005+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'google_sheet_to_bigquery', 'fetch_and_load_data_to_bigquery', 'manual__2024-04-03T13:24:24.379669+00:00', '--job-id', '108', '--raw', '--subdir', 'DAGS_FOLDER/dags/habidag.py', '--cfg-path', '/tmp/tmpc99jor7p']
[2024-04-03T13:24:29.009+0000] {standard_task_runner.py:88} INFO - Job 108: Subtask fetch_and_load_data_to_bigquery
[2024-04-03T13:24:29.078+0000] {task_command.py:423} INFO - Running <TaskInstance: google_sheet_to_bigquery.fetch_and_load_data_to_bigquery manual__2024-04-03T13:24:24.379669+00:00 [running]> on host 84784c125ee0
[2024-04-03T13:24:29.199+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='google_sheet_to_bigquery' AIRFLOW_CTX_TASK_ID='fetch_and_load_data_to_bigquery' AIRFLOW_CTX_EXECUTION_DATE='2024-04-03T13:24:24.379669+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-04-03T13:24:24.379669+00:00'
[2024-04-03T13:24:30.585+0000] {connection.py:269} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2024-04-03T13:24:30.592+0000] {base.py:83} INFO - Using connection ID 'google_cloud_default' for task execution.
[2024-04-03T13:24:30.594+0000] {bigquery.py:470} INFO - datasetId was not specified in `dataset_reference`. Will use default value datalake_anyeli5.
[2024-04-03T13:24:30.594+0000] {bigquery.py:470} INFO - projectId was not specified in `dataset_reference`. Will use default value papyrus-technical-test.
[2024-04-03T13:24:30.595+0000] {bigquery.py:481} INFO - Creating dataset: datalake_anyeli5 in project: papyrus-technical-test 
[2024-04-03T13:24:31.505+0000] {bigquery.py:485} INFO - Dataset created successfully.
[2024-04-03T13:24:31.836+0000] {connection.py:269} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2024-04-03T13:24:31.838+0000] {base.py:83} INFO - Using connection ID 'google_cloud_default' for task execution.
[2024-04-03T13:24:31.839+0000] {bigquery.py:1516} INFO - Creating table
[2024-04-03T13:24:32.838+0000] {bigquery.py:1538} INFO - Table papyrus-technical-test.datalake_anyeli5.transportistas created successfully
[2024-04-03T13:24:32.880+0000] {logging_mixin.py:188} INFO -    idTransportista     nombreEmpresa
0                1    Speedy Express
1                2    United Package
2                3  Federal Shipping
3                4     test cargue 1
[2024-04-03T13:24:32.882+0000] {logging_mixin.py:188} INFO - INSERT `papyrus-technical-test.datalake_anyeli5.transportistas` VALUES (1, 'Speedy Express'), (2, 'United Package'), (3, 'Federal Shipping'), (4, 'test cargue 1');
[2024-04-03T13:24:32.890+0000] {connection.py:269} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2024-04-03T13:24:32.893+0000] {base.py:83} INFO - Using connection ID 'google_cloud_default' for task execution.
[2024-04-03T13:24:32.955+0000] {bigquery.py:2811} INFO - Executing: {'query': {'query': "INSERT `papyrus-technical-test.datalake_anyeli5.transportistas` VALUES (1, 'Speedy Express'), (2, 'United Package'), (3, 'Federal Shipping'), (4, 'test cargue 1');", 'useLegacySql': False, 'priority': 'BATCH'}}'
[2024-04-03T13:24:32.956+0000] {bigquery.py:1613} INFO - Inserting job ***_adhoc_***_insert_data_transportistas_2024_04_03T13_24_24_379669_00_00_41b665dff119f221c59c45413e6a5b66
[2024-04-03T13:24:38.558+0000] {connection.py:269} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2024-04-03T13:24:38.572+0000] {base.py:83} INFO - Using connection ID 'google_cloud_default' for task execution.
[2024-04-03T13:24:38.582+0000] {bigquery.py:1516} INFO - Creating table
[2024-04-03T13:24:39.912+0000] {bigquery.py:1538} INFO - Table papyrus-technical-test.datalake_anyeli5.categorias created successfully
[2024-04-03T13:24:40.030+0000] {logging_mixin.py:188} INFO -    idCategoria  ...                                        descripcion
0            1  ...        Soft drinks, coffees, teas, beers, and ales
1            2  ...  Sweet and savory sauces, relishes, spreads, an...
2            3  ...                Desserts, candies, and sweet breads
3            4  ...                                            Cheeses
4            5  ...                Breads, crackers, pasta, and cereal
5            6  ...                                     Prepared meats
6            7  ...                          Dried fruit and bean curd
7            8  ...                                   Seaweed and fish

[8 rows x 3 columns]
[2024-04-03T13:24:40.043+0000] {logging_mixin.py:188} INFO - INSERT `papyrus-technical-test.datalake_anyeli5.categorias` VALUES (1, 'Beverages', 'Soft drinks, coffees, teas, beers, and ales'), (2, 'Condiments', 'Sweet and savory sauces, relishes, spreads, and seasonings'), (3, 'Confections', 'Desserts, candies, and sweet breads'), (4, 'Dairy Products', 'Cheeses'), (5, 'Grains & Cereals', 'Breads, crackers, pasta, and cereal'), (6, 'Meat & Poultry', 'Prepared meats'), (7, 'Produce', 'Dried fruit and bean curd'), (8, 'Seafood', 'Seaweed and fish');
[2024-04-03T13:24:40.059+0000] {connection.py:269} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2024-04-03T13:24:40.066+0000] {base.py:83} INFO - Using connection ID 'google_cloud_default' for task execution.
[2024-04-03T13:24:40.226+0000] {bigquery.py:2811} INFO - Executing: {'query': {'query': "INSERT `papyrus-technical-test.datalake_anyeli5.categorias` VALUES (1, 'Beverages', 'Soft drinks, coffees, teas, beers, and ales'), (2, 'Condiments', 'Sweet and savory sauces, relishes, spreads, and seasonings'), (3, 'Confections', 'Desserts, candies, and sweet breads'), (4, 'Dairy Products', 'Cheeses'), (5, 'Grains & Cereals', 'Breads, crackers, pasta, and cereal'), (6, 'Meat & Poultry', 'Prepared meats'), (7, 'Produce', 'Dried fruit and bean curd'), (8, 'Seafood', 'Seaweed and fish');", 'useLegacySql': False, 'priority': 'BATCH'}}'
[2024-04-03T13:24:40.230+0000] {bigquery.py:1613} INFO - Inserting job ***_adhoc_***_insert_data_categorias_2024_04_03T13_24_24_379669_00_00_1096e0600e45deba4f1c64bc8f0145a2
[2024-04-03T13:24:43.894+0000] {connection.py:269} WARNING - Connection schemes (type: google_cloud_platform) shall not contain '_' according to RFC3986.
[2024-04-03T13:24:43.904+0000] {base.py:83} INFO - Using connection ID 'google_cloud_default' for task execution.
[2024-04-03T13:24:43.905+0000] {bigquery.py:1516} INFO - Creating table
[2024-04-03T13:24:44.872+0000] {bigquery.py:1538} INFO - Table papyrus-technical-test.datalake_anyeli5.pedidos created successfully
[2024-04-03T13:24:44.927+0000] {logging_mixin.py:188} INFO -      idPedido idCliente  idEmpleado  ...  fechaEnvio idTransportista  flete
0       10258     ERNSH           1  ...  2013-07-23               1  14051
1       10270     WARTH           1  ...  2013-08-02               1  13654
2       10275     MAGAA           1  ...  2013-08-09               1   2693
3       10351     ERNSH           1  ...  2013-11-20               1  16233
4       10364     EASTC           1  ...  2013-12-04               1   7197
..        ...       ...         ...  ...         ...             ...    ...
825     10837     BERGS           9  ...  2015-01-23               3   1332
826     10889     RATTC           9  ...  2015-02-23               3  28061
827     10942     REGGC           9  ...  2015-03-18               3   1795
828     10963     FURIB           9  ...  2015-03-26               3     27
829     11058     BLAUS           9  ...                           3   3114

[830 rows x 8 columns]
[2024-04-03T13:24:44.929+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 217, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/dags/habidag.py", line 104, in fetch_and_load_data_to_bigquery
    column_value_scaped_special_characters = row[column['name']].replace("'", "\'")
AttributeError: 'int' object has no attribute 'replace'
[2024-04-03T13:24:44.947+0000] {taskinstance.py:1149} INFO - Marking task as UP_FOR_RETRY. dag_id=google_sheet_to_bigquery, task_id=fetch_and_load_data_to_bigquery, execution_date=20240403T132424, start_date=20240403T132428, end_date=20240403T132444
[2024-04-03T13:24:44.979+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 108 for task fetch_and_load_data_to_bigquery ('int' object has no attribute 'replace'; 7106)
[2024-04-03T13:24:45.003+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-04-03T13:24:45.033+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
